{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility snippets\n",
    "*\"Multimodal feature extraction for assistive technology: evaluation and dataset\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation\n",
    "The dataset was generated using the Pixtral-12b model from Mistral AI. In addition to the below prompt an image of the product was also provided to the model. The model's output was constrained to JSON and validated according to the schema. \n",
    "### Prompt\n",
    ">You are an expert assistive technology advisor. Please output a JSON object that adheres to the following schema. The object should represent an assistive technology item, which is given to you with the product's name in <ITEM_NAME></ITEM_NAME>, description in < DESCRIPTION >< /DESCRIPTION > and the image, with the following properties: {{detailed_description}}: A paragraph that describes the item in detail, which builds on the original description and image provided by the user. {{goals}}: An array of strings, where each string contains a life-related goal for a user of the item which motivates the use or purchase. The goals should be abstract and relate to high-level life objectives, rather than specific product features. {{healthcare_challenges}}: An array of strings, where each string contains a challenge defined as a disability and/or healthcare challenge associated with the item. These challenges can and should be both broadly descriptive and also include specific diagnoses relevant to the item. {{goal_classification}}: an object containing each of the following goal domains, [choice_and_control, daily_life, work, where_live, health_wellbeing, learning, relationships, social_community], and a boolean indicating if each domain is relevant to the item. Always output all domains in the JSON object. The goal domains are defined here: [choice_and_control: Support to make choices about one's life and minimise the need for external assistance.; daily_life: Support to participate in and manage the basic activities of daily life, including personal care, meal preparation, and managing one's living environment.; work: Support to participate in and maintain employment or self-employment.; where_live: Support to access and maintain suitable housing, including modifications; health_wellbeing: Support to directly maintain physical and mental health.; learning: Support to access enable or improve education and training opportunities, including formal and informal learning, and to develop skills for independent living.; relationships: Support to develop and maintain relationships with family, friends, and the community.; social_community: Support to participate in social and community activities, including recreation, leisure, and cultural pursuits.].{{user_age_minimum}}: An integer between 0 and 100 that estimates an absolute lower bound for a user's age such that the item is suitable (safe and able to be used). In terms of item size compatibility, enter 15 for an adult, 5 for a child and 0 for an infant as a lower bound. {{user_age_maximum}}: An integer between 0 and 100 that estimates an absolute upper bound for a user's age such that the item is suitable. {{estimated_cost}}: An integer number that indicates the estimated cost of the item, which should be a non-negative value. Make sure to include realistic values for each property. Do not include any keys in the JSON that are not mentioned above within {{}} or in the provided schema. \"<ITEM_NAME>{item['serienavneng']}</ITEM_NAME> < DESCRIPTION >{item['seriebeskrivelseeng']}< /DESCRIPTION >.\n",
    "\n",
    "### Schema\n",
    "> {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"detailed_description\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"An extended description of the item.\"\n",
    "      },\n",
    "      \"goals\": {\n",
    "        \"type\": \"array\",\n",
    "        \"description\": \"A list of goals a user would have that are associated or fulfilled with the item.\",\n",
    "        \"items\": {\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "      },\n",
    "      \"healthcare_challenges\": {\n",
    "        \"type\": \"array\",\n",
    "        \"description\": \"A list of disability and/or healthcare challenges associated with the item.\",\n",
    "        \"items\": {\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "      },\n",
    "      \"goal_classification\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"choice_and_control\": {\"type\": \"boolean\"},\n",
    "          \"daily_life\": {\"type\": \"boolean\"},\n",
    "          \"work\": {\"type\": \"boolean\"},\n",
    "          \"where_live\": {\"type\": \"boolean\"},\n",
    "          \"health_wellbeing\": {\"type\": \"boolean\"},\n",
    "          \"learning\": {\"type\": \"boolean\"},\n",
    "          \"relationships\": {\"type\": \"boolean\"},\n",
    "          \"social_community\": {\"type\": \"boolean\"}\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"choice_and_control\",\n",
    "          \"daily_life\",\n",
    "          \"work\",\n",
    "          \"where_live\",\n",
    "          \"health_wellbeing\",\n",
    "          \"learning\",\n",
    "          \"relationships\",\n",
    "          \"social_community\"\n",
    "        ]\n",
    "      },\n",
    "      \"user_age_minimum\": {\n",
    "        \"type\": \"integer\",\n",
    "        \"description\": \"The absolute minimum suitable age for a user of the product. To approximate an infant, enter 0; for a child, enter 5. To approximate an adult, enter 15.\",\n",
    "        \"minimum\": 0,\n",
    "        \"maximum\": 100\n",
    "      },\n",
    "      \"user_age_maximum\": {\n",
    "        \"type\": \"integer\",\n",
    "        \"description\": \"The absolute maximum suitable age for a user of the product. To approximate an infant, enter 0; for a child, enter 5. To approximate an adult, enter 15.\",\n",
    "        \"minimum\": 0,\n",
    "        \"maximum\": 100\n",
    "      },\n",
    "      \"estimated_cost\": {\n",
    "        \"type\": \"number\",\n",
    "        \"description\": \"The estimated cost of the item.\",\n",
    "        \"minimum\": 0\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"detailed_description\", \"goals\", \"healthcare_challenges\", \"goal_classification\", \"user_age_minimum\", \"user_age_maximum\", \"estimated_cost\"]\n",
    "    }\n",
    "\n",
    "### Validation:\n",
    "Uses the [jsonschema library](https://github.com/python-jsonschema/jsonschema). The function parameter 'data' is the model's JSON output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonschema\n",
    "\n",
    "def validate_json(data, schema, id):\n",
    "    try:\n",
    "        jsonschema.validate(instance=data, schema=schema)\n",
    "        print(\"JSON data is valid.\")\n",
    "        return True\n",
    "    except jsonschema.exceptions.ValidationError as e:\n",
    "        print(f\"JSON data for item {id} is invalid:\", e.message)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Multimodal experimental dataset production\n",
    "The production prompt above was modified to remove refrences to an attached image, item name or item description depending on the experiment type. Model output is available in the following files\\:\n",
    "- Text only: ablation_text_only.json\n",
    "- Images only: ablation_images_only.json\n",
    "- Image and title: ablation_image_and_title.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Annotator agreement\n",
    "This section contains code snippets for calculating annotator agreement on boolean classification activities.\n",
    "### Cohen's kappa (example between annotators and LLM)\n",
    "Uses the [scikit-learn library](https://scikit-learn.org). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def alignment_all(merged_file, categories):\n",
    "\n",
    "    scores_dict = {category: {'user': [], 'llm': []} for category in categories}\n",
    "    scores_user = []\n",
    "    scores_llm = []\n",
    "    with open(merged_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    with open('annotation_subset_llm_outputs.json', 'r') as file:\n",
    "        full_dataset = json.load(file)\n",
    "    \n",
    "    for each in data:\n",
    "        for item in full_dataset:\n",
    "            if each['id'] == item['id']:\n",
    "                llm_scores = item['LLM_output']['goal_classification']\n",
    "        \n",
    "        for category in categories:\n",
    "            scores_dict[category]['user'].append(each['LLM_output']['goal_classification'][category])\n",
    "            scores_user.append(each['LLM_output']['goal_classification'][category])\n",
    "            scores_dict[category]['llm'].append(llm_scores[category])\n",
    "            scores_llm.append(llm_scores[category])\n",
    "\n",
    "    # Calculate and print Cohen's kappa for each category\n",
    "    for category in categories:\n",
    "        kappa = cohen_kappa_score(scores_dict[category]['user'], scores_dict[category]['llm'])\n",
    "        print(f\"Kappa for {category}: {kappa}\")\n",
    "    \n",
    "    print(f\"All category Cohen's Kappa is {cohen_kappa_score(scores_user, scores_llm)}\")\n",
    "\n",
    "categories = [\n",
    "    'choice_and_control',\n",
    "    'daily_life',\n",
    "    'work',\n",
    "    'where_live',\n",
    "    'health_wellbeing',\n",
    "    'learning',\n",
    "    'relationships',\n",
    "    'social_community'\n",
    "]\n",
    "\n",
    "# Annotator A - LLM\n",
    "alignment_all('annotator_a_annotations.json', categories)\n",
    "# Annotator A - LLM Unprimed\n",
    "alignment_all('annotator_a_no_priming_annotations.json', categories)\n",
    "# Annotator B - LLM\n",
    "alignment_all('annotator_b_annotations.json', categories)\n",
    "# Annotator B - LLM Unprimed\n",
    "alignment_all('annotator_b_no_priming_annotations.json', categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohen's kappa inter-annotator agreement\n",
    " Additional files for calculating the kappas between annotators are supplied as:\n",
    "- annotator_a_crosscheck.json (annotator A's overlap of tasks assigned to B)\n",
    "- annotator_b_crosscheck.json (annotator B's overlap of tasks assigned to A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def inter_annotator_agreement():\n",
    "    # Create a dictionary to store booleans\n",
    "    scores_dict = {category: {'annotator_a': [], 'annotator_b': []} for category in categories}\n",
    "\n",
    "    # Add annotator A's data\n",
    "    with open('annotator_a_crosscheck.json', 'r') as file:\n",
    "        a_crosscheck_data = json.load(file)\n",
    "    with open('annotator_b_annotations.json', 'r') as file:\n",
    "        b_annotations = json.load(file)\n",
    "    \n",
    "    for each in a_crosscheck_data:\n",
    "        for comparison in b_annotations:\n",
    "            if each['id'] == comparison['id']:\n",
    "                b_annotations_dict = comparison['LLM_output']['goal_classification']\n",
    "        \n",
    "        for category in categories:\n",
    "            scores_dict[category]['annotator_a'].append(each['LLM_output']['goal_classification'][category])\n",
    "            scores_dict[category]['annotator_b'].append(b_annotations_dict[category])\n",
    "\n",
    "    # Add annotator B's data\n",
    "    with open('annotator_b_crosscheck.json', 'r') as file:\n",
    "        b_crosscheck_data = json.load(file)\n",
    "    with open('annotator_a_annotations.json', 'r') as file:\n",
    "        a_annotations = json.load(file)\n",
    "    \n",
    "    for each in b_crosscheck_data:\n",
    "        for comparison in a_annotations:\n",
    "            if each['id'] == comparison['id']:\n",
    "                a_annotations_dict = comparison['LLM_output']['goal_classification']\n",
    "        \n",
    "        for category in categories:\n",
    "            scores_dict[category]['annotator_b'].append(each['LLM_output']['goal_classification'][category])\n",
    "            scores_dict[category]['annotator_a'].append(a_annotations_dict[category])\n",
    "\n",
    "    combined_a = []\n",
    "    combined_b = []\n",
    "    for category in categories:\n",
    "        kappa = cohen_kappa_score(scores_dict[category]['annotator_a'], scores_dict[category]['annotator_b'])\n",
    "        combined_a.extend(scores_dict[category]['annotator_a'])\n",
    "        combined_b.extend(scores_dict[category]['annotator_b'])\n",
    "        print(f\"Kappa for {category}: {kappa}\")\n",
    "    \n",
    "    print(f\"All category Cohen's Kappa is {cohen_kappa_score(combined_a, combined_b)}\")\n",
    "    \n",
    "    \n",
    "\n",
    "inter_annotator_agreement()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## BERTScore \n",
    "The [BERTScore library](https://github.com/Tiiiger/bert_score) was used to calculate semantic similarity between text. This encompasses inter-annotator similarity, annotator-LLM similarity and similarity between generations in our ablation study. The examples below calculate the BERTScore for the ablation study. The code can easily be modified to reproduce annotator similarity scores using annotation objects included in this directory. \n",
    "\n",
    "Hash: roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.46.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify to use JSON reproducibility files. Ablation needs to use aggregated annotations, not LLM generations, as constants and ablations are the candidates. \n",
    "\n",
    "import json\n",
    "from bert_score import score, plot_example\n",
    "\n",
    "def bert_score_text_only(reference_file, candidate_file):\n",
    "    references_descriptions = []\n",
    "    candidates_descriptions = [] \n",
    "\n",
    "    references_goals = []\n",
    "    candidates_goals = [] \n",
    "\n",
    "    references_challenges = []\n",
    "    candidates_challenges = [] \n",
    "\n",
    "    with open(reference_file, 'r') as ref:\n",
    "        reference_data = json.load(ref)\n",
    "    \n",
    "    with open(candidate_file, 'r') as can:\n",
    "        candidate_data = json.load(can)\n",
    "    \n",
    "    for each in reference_data:\n",
    "        references_descriptions.append(each['LLM_output']['detailed_description'])\n",
    "        references_goals.append(each['LLM_output']['goals'])\n",
    "        references_challenges.append(each['LLM_output']['healthcare_challenges'])\n",
    "        for item in candidate_data:\n",
    "            if each['id'] == item['id']:\n",
    "                candidates_descriptions.append(item['LLM_output']['detailed_description'])\n",
    "                candidates_goals.append(item['LLM_output']['goals'])\n",
    "                candidates_challenges.append(item['LLM_output']['healthcare_challenges'])\n",
    "        \n",
    "\n",
    "    P, R, F1 = score(references_descriptions, candidates_descriptions, lang='en', verbose=True)\n",
    "\n",
    "    P1, R1, F1_1 = score([', '.join(sublist) for sublist in references_goals], [', '.join(sublist) for sublist in candidates_goals], lang='en', verbose=True)\n",
    "\n",
    "    P2, R2, F1_2 = score([', '.join(sublist) for sublist in references_challenges], [', '.join(sublist) for sublist in candidates_challenges], lang='en', verbose=True)\n",
    "    \n",
    "    mean_results = {\"Descriptions precision\": P.mean(), \"Descriptions recall\": R.mean(), \"Descriptions F1\": F1.mean(), \"Goals precision\": P1.mean(), \"Goals recall\": R1.mean(), \"Goals F1\": F1_1.mean(),\"Challenges precision\": P2.mean(), \"Challenges recall\": R2.mean(), \"Challenges F1\": F1_2.mean()}\n",
    "    median_results = {\"Descriptions precision\": P.median(), \"Descriptions recall\": R.median(), \"Descriptions F1\": F1.median(), \"Goals precision\": P1.median(), \"Goals recall\": R1.median(), \"Goals F1\": F1_1.median(),\"Challenges precision\": P2.median(), \"Challenges recall\": R2.median(), \"Challenges F1\": F1_2.median()}\n",
    "    minimum_results = {\"Descriptions precision\": P.min(), \"Descriptions recall\": R.min(), \"Descriptions F1\": F1.min(), \"Goals precision\": P1.min(), \"Goals recall\": R1.min(), \"Goals F1\": F1_1.min(),\"Challenges precision\": P2.min(), \"Challenges recall\": R2.min(), \"Challenges F1\": F1_2.min()}\n",
    "\n",
    "    all_results = {\"mean_results\": mean_results, \"median_results\": median_results, \"minimum_results\": minimum_results}\n",
    "    some_results = {\"descriptions_f1\": mean_results['Descriptions F1'], \"goals_f1\": mean_results['Goals F1'], \"challenges_f1\": mean_results['Challenges F1']}\n",
    "\n",
    "    return some_results\n",
    "\n",
    "annotator_a_llm = bert_score_text_only('annotator_a_annotations.json', 'annotation_subset_llm_outputs.json')\n",
    "annotator_b_llm = bert_score_text_only('annotator_b_annotations.json', 'annotation_subset_llm_outputs.json')\n",
    "inter_annotator = bert_score_text_only('crosscheck_merged.json','merged_annotations.json')\n",
    "ablation_image = bert_score_text_only('merged_annotations.json','ablation_images_only.json')\n",
    "ablation_text = bert_score_text_only('merged_annotations.json','ablation_text_only.json')\n",
    "ablation_image_title = bert_score_text_only('merged_annotations.json','ablation_image_and_title.json')\n",
    "\n",
    "\n",
    "print(f\"Annotator A - LLM similarity: {annotator_a_llm}\")\n",
    "print(f\"Annotator B - LLM similarity: {annotator_b_llm}\")\n",
    "print(f\"Inter-annotator similarity: {inter_annotator}\")\n",
    "print(f\"Ablation study - image only to gold standard: {ablation_image}\")\n",
    "print(f\"Ablation study - text only to gold standard: {ablation_text}\")\n",
    "print(f\"Ablation study - image + item title only to gold standard: {ablation_image_title}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative score\n",
    "Annotators were given the subsequent instructions to rate generative candidates on a qualitative basis.\n",
    "> Rate the accuracy and comprehensiveness of the generative output after annotation on a scale of 1-3 where 1 requires signifiant revision, 2 requires moderate revision and 3 requires no or a limited amount of revision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
